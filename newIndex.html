<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Recorder</title>
</head>

<body>
    <button id="startBtn">Start Recording</button>
    <button id="stopBtn" disabled>Stop Recording</button>
    <audio id="audioPlayback" controls></audio>
    <audio id="audioPlayer" controls hidden></audio>

    <script src="https://cdn.socket.io/4.0.0/socket.io.min.js"></script>
    <script>
        let mediaRecorder;
        let audioChunks = [];
        let audioContext;
        let analyser;
        let microphone;
        let scriptProcessor;
        const silenceDelay = 2000; // 2 seconds

        document.getElementById('startBtn').addEventListener('click', startRecording);
        document.getElementById('stopBtn').addEventListener('click', stopRecording);

        function startRecording() {
            let silenceStart;
            console.log("starting recording")
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    mediaRecorder = new MediaRecorder(stream);
                    mediaRecorder.ondataavailable = event => {
                        audioChunks.push(event.data);
                    };
                    mediaRecorder.onstop = () => {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                        const audioUrl = URL.createObjectURL(audioBlob);
                        const audio = document.getElementById('audioPlayback');
                        audio.src = audioUrl;
                        audioChunks = [];
                        sendAudioToBackend(audioBlob);
                    };

                    mediaRecorder.start();
                    document.getElementById('startBtn').disabled = true;
                    document.getElementById('stopBtn').disabled = false;

                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    analyser = audioContext.createAnalyser();
                    microphone = audioContext.createMediaStreamSource(stream);
                    scriptProcessor = audioContext.createScriptProcessor(256, 1, 1);

                    analyser.fftSize = 512;
                    microphone.connect(analyser);
                    analyser.connect(scriptProcessor);
                    scriptProcessor.connect(audioContext.destination);

                    scriptProcessor.onaudioprocess = function (event) {
                        const buffer = event.inputBuffer.getChannelData(0);
                        const now = performance.now();

                        let sum = 0;
                        for (let i = 0; i < buffer.length; i++) {
                            sum += buffer[i] * buffer[i];
                        }
                        const rms = Math.sqrt(sum / buffer.length);
                        // console.log(rms)
                        // console.log(silenceStart)

                        if (rms < 0.01) {
                            // console.log("in the loop")
                            if (!silenceStart) {
                                silenceStart = now;
                            } else if (now - silenceStart > silenceDelay) {
                                console.log("in the stop")
                                stopRecording();
                            }
                        } else {
                            silenceStart = null;
                        }
                    };
                })
                .catch(err => console.error('Error accessing microphone:', err));
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== "inactive") {
                mediaRecorder.stop();
            }
            if (audioContext && audioContext.state !== "closed") {
                scriptProcessor.disconnect();
                analyser.disconnect();
                microphone.disconnect();
                audioContext.close();
            }
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
        }

        function sendAudioToBackend(audioBlob) {
            const formData = new FormData();
            formData.append('audio', audioBlob, 'recording.wav');

            // fetch('http://localhost:3000/upload', {
            fetch('/upload', {

                method: 'POST',
                body: formData
            })
                .then(response => response.json())
                .then(data => console.log('Success:', data))
                .catch(error => console.error('Error:', error));
        }

        document.addEventListener('DOMContentLoaded', function () {
            var socket = io();

            socket.on('connect', function () {
                console.log('Connected!');
            });

            // socket.on('display_text', function (data) {
            //     document.getElementById('userText').textContent = "User: " + data.user_text;
            //     document.getElementById('botText').textContent = "Bot: " + data.bot_text;
            // });

            socket.on('audio_response', function (data) {
                console.log('Received audio:', data);
                let audioPlayer = document.getElementById('audioPlayer');
                audioPlayer.src = 'data:audio/mp3;base64,' + data.data;
                audioPlayer.play();

                audioPlayer.onended = function () {
                    console.log('Audio playback finished');
                    socket.emit('audio_finished');
                    startRecording();
                };
            });
            socket.on('audio_error', function (data) {
                console.error('Error fetching audio:', data.error);
            });
        });
    </script>
</body>

</html>